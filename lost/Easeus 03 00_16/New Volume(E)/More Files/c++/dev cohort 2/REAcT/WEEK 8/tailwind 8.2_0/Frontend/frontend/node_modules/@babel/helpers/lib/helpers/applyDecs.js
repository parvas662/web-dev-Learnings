"use strict";Object.defineProperty(exports, "__esModule", {value: true});/* eslint max-len: 0 */

var _index = require('../index');
















var _flow = require('../plugins/flow');


















var _typescript = require('../plugins/typescript');












var _tokenizer = require('../tokenizer');
var _keywords = require('../tokenizer/keywords');
var _state = require('../tokenizer/state');
var _types = require('../tokenizer/types');
var _charcodes = require('../util/charcodes');
var _base = require('./base');












var _expression = require('./expression');





var _lval = require('./lval');












var _util = require('./util');

 function parseTopLevel() {
  parseBlockBody(_types.TokenType.eof);
  _base.state.scopes.push(new (0, _state.Scope)(0, _base.state.tokens.length, true));
  if (_base.state.scopeDepth !== 0) {
    throw new Error(`Invalid scope depth at end of file: ${_base.state.scopeDepth}`);
  }
  return new (0, _index.File)(_base.state.tokens, _base.state.scopes);
} exports.parseTopLevel = parseTopLevel;

// Parse a single statement.
//
// If expecting a statement and finding a slash operator, parse a
// regular expression literal. This is to handle cases like
// `if (foo) /blah/.exec(foo)`, where looking at the previous token
// does not help.

 function parseStatement(declaration) {
  if (_base.isFlowEnabled) {
    if (_flow.flowTryParseStatement.call(void 0, )) {
      return;
    }
  }
  if (_tokenizer.match.call(void 0, _types.TokenType.at)) {
    parseDecorators();
  }
  parseStatementContent(declaration);
} exports.parseStatement = parseStatement;

function parseStatementContent(declaration) {
  if (_base.isTypeScriptEnabled) {
    if (_typescript.tsTryParseStatementContent.call(void 0, )) {
      return;
    }
  }

  const starttype = _base.state.type;

  // Most types of statements are recognized by the keyword they
  // start with. Many are trivial to parse, some require a bit of
  // complexity.

  switch (starttype) {
    case _types.TokenType._break:
    case _types.TokenType._continue:
      parseBreakContinueStatement();
      return;
    case _types.TokenType._debugger:
      parseDebuggerStatement();
      return;
    case _types.TokenType._do:
      parseDoStatement();
      return;
    case _types.TokenType._for:
      parseForStatement();
      return;
    case _types.TokenType._function:
      if (_tokenizer.lookaheadType.call(void 0, ) === _types.TokenType.dot) break;
      if (!declaration) _util.unexpected.call(void 0, );
      parseFunctionStatement();
      return;

    case _types.TokenType._class:
      if (!declaration) _util.unexpected.call(void 0, );
      parseClass(true);
      return;

    case _types.TokenType._if:
      parseIfStatement();
      return;
    case _types.TokenType._return:
      parseReturnStatement();
      return;
    case _types.TokenType._switch:
      parseSwitchStatement();
      return;
    case _types.TokenType._throw:
      parseThrowStatement();
      return;
    case _types.TokenType._try:
      parseTryStatement();
      return;

    case _types.TokenType._let:
    case _types.TokenType._const:
      if (!declaration) _util.unexpected.call(void 0, ); // NOTE: falls through to _var

    case _types.TokenType._var:
      parseVarStatement(starttype !== _types.TokenType._var);
      return;

    case _types.TokenType._while:
      parseWhileStatement();
      return;
    case _types.TokenType.braceL:
      parseBlock();
      return;
    case _types.TokenType.semi:
      parseEmptyStatement();
      return;
    case _types.TokenType._export:
    case _types.TokenType._import: {
      const nextType = _tokenizer.lookaheadType.call(void 0, );
      if (nextType === _types.TokenType.parenL || nextType === _types.TokenType.dot) {
        break;
      }
      _tokenizer.next.call(void 0, );
      if (starttype === _types.TokenType._import) {
        parseImport();
      } else {
        parseExport();
      }
      return;
    }
    case _types.TokenType.name:
      if (_base.state.contextualKeyword === _keywords.ContextualKeyword._async) {
        const functionStart = _base.state.start;
        // peek ahead and see if next token is a function
        const snapshot = _base.state.snapshot();
        _tokenizer.next.call(void 0, );
        if (_tokenizer.match.call(void 0, _types.TokenType._function) && !_util.canInsertSemicolon.call(void 0, )) {
          _util.expect.call(void 0, _types.TokenType._function);
          parseFunction(functionStart, true);
          return;
        } else {
          _base.state.restoreFromSnapshot(snapshot);
        }
      } else if (
        _base.state.contextualKeyword === _keywords.ContextualKeyword._using &&
        !_util.hasFollowingLineBreak.call(void 0, ) &&
        // Statements like `using[0]` and `using in foo` aren't actual using
        // declarations.
        _tokenizer.lookaheadType.call(void 0, ) === _types.TokenType.name
      ) {
        parseVarStatement(true);
        return;
      } else if (startsAwaitUsing()) {
        _util.expectContextual.call(void 0, _keywords.ContextualKeyword._await);
        parseVarStatement(true);
        return;
      }
    default:
      // Do nothing.
      break;
  }

  // If the statement does not start with a statement keyword or a
  // brace, it's an ExpressionStatement or LabeledStatement. We
  // simply start parsing an expression, and afterwards, if the
  // next token is a colon and the expression was a simple
  // Identifier node, we switch to interpreting it as a label.
  const initialTokensLength = _base.state.tokens.length;
  _expression.parseExpression.call(void 0, );
  let simpleName = null;
  if (_base.state.tokens.length === initialTokensLength + 1) {
    const token = _base.state.tokens[_base.state.tokens.length - 1];
    if (token.type === _types.TokenType.name) {
      simpleName = token.contextualKeyword;
    }
  }
  if (simpleName == null) {
    _util.semicolon.call(void 0, );
    return;
  }
  if (_tokenizer.eat.call(void 0, _types.TokenType.colon)) {
    parseLabeledStatement();
  } else {
    // This was an identifier, so we might want to handle flow/typescript-specific cases.
    parseIdentifierStatement(simpleName);
  }
}

/**
 * Determine if we're positioned at an `await using` declaration.
 *
 * Note that this can happen either in place of a regular variable declaration
 * or in a loop body, and in both places, there are similar-looking cases where
 * we need to return false.
 *
 * Examples returning true:
 * await using foo = bar();
 * for (await using a of b) {}
 *
 * Examples returning false:
 * await using
 * await using + 1
 * await using instanceof T
 * for (await using;;) {}
 *
 * For now, we early return if we don't see `await`, then do a simple
 * backtracking-based lookahead for the `using` and identifier tokens. In the
 * future, this could be optimized with a character-based approach.
 */
function startsAwaitUsing() {
  if (!_util.isContextual.call(void 0, _keywords.ContextualKeyword._await)) {
    return false;
  }
  const snapshot = _base.state.snapshot();
  // await
  _tokenizer.next.call(void 0, );
  if (!_util.isContextual.call(void 0, _keywords.ContextualKeyword._using) || _util.hasPrecedingLineBreak.call(void 0, )) {
    _base.state.restoreFromSnapshot(snapshot);
    return false;
  }
  // using
  _tokenizer.next.call(void 0, );
  if (!_tokenizer.match.call(void 0, _types.TokenType.name) || _util.hasPrecedingLineBreak.call(void 0, )) {
    _base.state.restoreFromSnapshot(snapshot);
    return false;
  }
  _base.state.restoreFromSnapshot(snapshot);
  return true;
}

 function parseDecorators() {
  while (_tokenizer.match.call(void 0, _types.TokenType.at)) {
    parseDecorator();
  }
} exports.parseDecorators = parseDecorators;

function parseDecorator() {
  _tokenizer.next.call(void 0, );
  if (_tokenizer.eat.call(void 0, _types.TokenType.parenL)) {
    _expression.parseExpression.call(void 0, );
    _util.expect.call(void 0, _types.TokenType.parenR);
  } else {
    _expression.parseIdentifier.call(void 0, );
    while (_tokenizer.eat.call(void 0, _types.TokenType.dot)) {
      _expression.parseIdentifier.call(void 0, );
    }
    parseMaybeDecoratorArguments();
  }
}

function parseMaybeDecoratorArguments() {
  if (_base.isTypeScriptEnabled) {
    _typescript.tsParseMaybeDecoratorArguments.call(void 0, );
  } else {
    baseParseMaybeDecoratorArguments();
  }
}

 function baseParseMaybeDecoratorArguments() {
  if (_tokenizer.eat.call(void 0, _types.TokenType.parenL)) {
    _expression.parseCallExpressionArguments.call(void 0, );
  }
} exports.baseParseMaybeDecoratorArguments = baseParseMaybeDecoratorArguments;

function parseBreakContinueStatement() {
  _tokenizer.next.call(void 0, );
  if (!_util.isLineTerminator.call(void 0, )) {
    _expression.parseIdentifier.call(void 0, );
    _util.semicolon.call(void 0, );
  }
}

function parseDebuggerStatement() {
  _tokenizer.next.call(void 0, );
  _util.semicolon.call(void 0, );
}

function parseDoStatement() {
  _tokenizer.next.call(void 0, );
  parseStatement(false);
  _util.expect.call(void 0, _types.TokenType._while);
  _expression.parseParenExpression.call(void 0, );
  _tokenizer.eat.call(void 0, _types.TokenType.semi);
}

function parseForStatement() {
  _base.state.scopeDepth++;
  const startTokenIndex = _base.state.tokens.length;
  parseAmbiguousForStatement();
  const endTokenIndex = _base.state.tokens.length;
  _base.state.scopes.push(new (0, _state.Scope)(startTokenIndex, endTokenIndex, false));
  _base.state.scopeDepth--;
}

/**
 * Determine if this token is a `using` declaration (explicit resource
 * management) as part of a loop.
 * https://github.com/tc39/proposal-explicit-resource-management
 */
function isUsingInLoop() {
  if (!_util.isContextual.call(void 0, _keywords.ContextualKeyword._using)) {
    return false;
  }
  // This must be `for (using of`, where `using` is the name of the loop
  // variable.
  if (_util.isLookaheadContextual.call(void 0, _keywords.ContextualKeyword._of)) {
    return false;
  }
  return true;
}

// Disambiguating between a `for` and a `for`/`in` or `for`/`of`
// loop is non-trivial. Basically, we have to parse the init `var`
// statement or expression, disallowing the `in` operator (see
// the second parameter to `parseExpression`), and then check
// whether the next token is `in` or `of`. When there is no init
// part (semicolon immediately after the opening parenthesis), it
// is a regular `for` loop.
function parseAmbiguousForStatement() {
  _tokenizer.next.call(void 0, );

  let forAwait = false;
  if (_util.isContextual.call(void 0, _keywords.ContextualKeyword._await)) {
    forAwait = true;
    _tokenizer.next.call(void 0, );
  }
  _util.expect.call(void 0, _types.TokenType.parenL);

  if (_tokenizer.match.call(void 0, _types.TokenType.semi)) {
    if (forAwait) {
      _util.unexpected.call(void 0, );
    }
    parseFor();
    return;
  }

  const isAwaitUsing = startsAwaitUsing();
  if (isAwaitUsing || _tokenizer.match.call(void 0, _types.TokenType._var) || _tokenizer.match.call(void 0, _types.TokenType._let) || _tokenizer.match.call(void 0, _types.TokenType._const) || isUsingInLoop()) {
    if (isAwaitUsing) {
      _util.expectContextual.call(void 0, _keywords.ContextualKeyword._await);
    }
    _tokenizer.next.call(void 0, );
    parseVar(true, _base.state.type !== _types.TokenType._var);
    if (_tokenizer.match.call(void 0, _types.TokenType._in) || _util.isContextual.call(void 0, _keywords.ContextualKeyword._of)) {
      parseForIn(forAwait);
      return;
    }
    parseFor();
    return;
  }

  _expression.parseExpression.call(void 0, true);
  if (_tokenizer.match.call(void 0, _types.TokenType._in) || _util.isContextual.call(void 0, _keywords.ContextualKeyword._of)) {
    parseForIn(forAwait);
    return;
  }
  if (forAwait) {
    _util.unexpected.call(void 0, );
  }
  parseFor();
}

function parseFunctionStatement() {
  const functionStart = _base.state.start;
  _tokenizer.next.call(void 0, );
  parseFunction(functionStart, true);
}

function parseIfStatement() {
  _tokenizer.next.call(void 0, );
  _expression.parseParenExpression.call(void 0, );
  parseStatement(false);
  if (_tokenizer.eat.call(void 0, _types.TokenType._else)) {
    parseStatement(false);
  }
}

function parseReturnStatement() {
  _tokenizer.next.call(void 0, );

  // In `return` (and `break`/`continue`), the keywords with
  // optional arguments, we eagerly look for a semicolon or the
  // possibility to insert one.

  if (!_util.isLineTerminator.call(void 0, )) {
    _expression.parseExpression.call(void 0, );
    _util.semicolon.call(void 0, );
  }
}

function parseSwitchStatement() {
  _tokenizer.next.call(void 0, );
  _expression.parseParenExpression.call(void 0, );
  _base.state.scopeDepth++;
  const startTokenIndex = _base.state.tokens.length;
  _util.expect.call(void 0, _types.TokenType.braceL);

  // Don't bother validation; just go through any sequence of cases, defaults, and statements.
  while (!_tokenizer.match.call(void 0, _types.TokenType.braceR) && !_base.state.error) {
    if (_tokenizer.match.call(void 0, _types.TokenType._case) || _tokenizer.match.call(void 0, _types.TokenType._default)) {
      const isCase = _tokenizer.match.call(void 0, _types.TokenType._case);
      _tokenizer.next.call(void 0, );
      if (isCase) {
        _expression.parseExpression.call(void 0, );
      }
      _util.expect.call(void 0, _types.TokenType.colon);
    } else {
      parseStatement(true);
    }
  }
  _tokenizer.next.call(void 0, ); // Closing brace
  const endTokenIndex = _base.state.tokens.length;
  _base.state.scopes.push(new (0, _state.Scope)(startTokenIndex, endTokenIndex, false));
  _base.state.scopeDepth--;
}

function parseThrowStatement() {
  _tokenizer.next.call(void 0, );
  _expression.parseExpression.call(void 0, );
  _util.semicolon.call(void 0, );
}

function parseCatchClauseParam() {
  _lval.parseBindingAtom.call(void 0, true /* isBlockScope */);

  if (_base.isTypeScriptEnabled) {
    _typescript.tsTryParseTypeAnnotation.call(void 0, );
  }
}

funct